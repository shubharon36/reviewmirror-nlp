\documentclass[11pt]{article}
\usepackage[a4paper,margin=1in]{geometry}
\usepackage{hyperref}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{titlesec}
\usepackage{enumitem}
\usepackage{amsmath, amssymb}

\title{Milestone 1: Data \& Literature Plan\\
\large Temporal Opinion Drift in Product Reviews}
\author{Team Name Here}
\date{\today}

\begin{document}
\maketitle

\begin{abstract}
Users' expressed opinions in product reviews evolve over time due to preference shifts, product lifecycle effects, or strategic behavior. This milestone chooses a public dataset, defines the data schema and pipeline, and summarizes key literature that motivates our representation and evaluation for user-level ``opinion drift.''
\end{abstract}

\section{Problem \& Objectives}
We study how individual users' sentiments and writing tones change across their review history. Objectives: (1) analyze temporal patterns of opinions in longitudinal review data; (2) define a representation to compare a user's sentiment/style over time; (3) quantify and visualize drift with interpretable signals; (4) justify modeling and evaluation choices grounded in prior work.

\section{Dataset Selection (Primary \& Backup)}
\paragraph{Primary: Amazon Review Data (2018, UCSD).}
The 2018 release contains $\sim$233M reviews spanning May 1996--Oct 2018 with fields such as \texttt{reviewerID}, \texttt{asin}, \texttt{reviewText}, \texttt{overall} (stars), and \texttt{unixReviewTime}. It also offers a \emph{5-core} subset (75.26M reviews) where each user and item has $\ge 5$ reviews, ideal for longitudinal user analysis; per-category splits include \emph{Electronics} (20.99M reviews).\footnote{See official page for schema, 5-core, and per-category counts.}
We will use the \textbf{Electronics 5-core} subset to ensure enough reviews per user while keeping compute manageable.

\paragraph{Backup: Yelp Open Dataset.}
Yelp's open dataset provides JSON files for reviews (\texttt{review\_id}, \texttt{user\_id}, \texttt{business\_id}, \texttt{stars}, \texttt{date}, \texttt{text}), businesses, and users, and is widely used for educational research. It is suitable as a secondary domain if we need cross-domain validation (services vs.\ products).

\paragraph{Optional cross-domain (aspect-rich): BeerAdvocate.}
Beer reviews include per-aspect scores (appearance, aroma, palate, taste, overall) over 10+ years, enabling aspect-specific drift analyses.

\section{Data Model \& Schema}
We will curate a tidy table with one row per review:
\begin{center}
\begin{tabular}{ll}
\toprule
Field & Description\\
\midrule
\texttt{user\_id} & Reviewer identifier (\texttt{reviewerID} / \texttt{user\_id})\\
\texttt{item\_id} & Product/business identifier (\texttt{asin} / \texttt{business\_id})\\
\texttt{ts} & Timestamp (from \texttt{unixReviewTime} or \texttt{date})\\
\texttt{text} & Raw review text\\
\texttt{stars} & Star rating (1--5)\\
\texttt{category} & (Optional) high-level category for stratification\\
\texttt{helpful\_votes} & (Optional) helpfulness/engagement signal\\
\bottomrule
\end{tabular}
\end{center}
For downstream features we will compute: (i) \emph{text sentiment} (lexicon baseline, e.g., VADER; and transformer-based polarity later), (ii) \emph{style/tone} proxies (exclamation density, first-person ratio, subjectivity/readability), and (iii) time indices (calendar month, time-since-first-review).

\section{Preprocessing Pipeline}
\begin{enumerate}[leftmargin=*, itemsep=2pt]
\item \textbf{Ingest} per-category JSON (gzipped) $\rightarrow$ dataframe with fields above.
\item \textbf{Filter} language to English; drop empty/near-duplicate texts (optional MinHash).
\item \textbf{User coverage} keep users with $\ge k$ reviews (default $k=5$) to enable trajectories.
\item \textbf{Normalize time} convert to UTC timestamps; derive month bins; sort per user.
\item \textbf{Light labeling} compute baseline text polarity (e.g., VADER compound $\in[-1,1]$) and standardize to $z$-scores within user for comparability.
\item \textbf{Export} two artifacts: \texttt{reviews.parquet} (row-level) and \texttt{user\_trajectories.parquet} (per-user sequences with features per time bin).
\end{enumerate}

\section{Representation of Opinion Trajectories}
For each user $u$, define a sequence $\{(t_i, s_i, r_i, \mathbf{f}_i)\}_{i=1}^{n_u}$ where $s_i$ is text polarity, $r_i$ is (normalized) stars, and $\mathbf{f}_i$ are style features. We study:
\begin{itemize}[leftmargin=*, itemsep=2pt]
\item \textbf{Hybrid sentiment:} $h_i = \alpha s_i + (1-\alpha)\,\tilde r_i$, $\alpha\in[0,1]$, $\tilde r_i$ is stars mapped to $[-1,1]$.
\item \textbf{Smoothed path:} $\bar h_{t} = \mathrm{EWMA}_\lambda(h_i)$ within sliding windows.
\item \textbf{Drift magnitude:} $\mathrm{DriftIdx}(u)= \bar h_{T}-\bar h_{0}$ and \emph{slope} via robust regression of $h$ on time.
\item \textbf{Change points:} detected via ADWIN/Page--Hinkley on $h_i$; optional dynamic topic/style evolution for interpretation.
\end{itemize}

\section{Quantifying \& Visualizing Drift}
\paragraph{Quantification.} (a) signed slope; (b) total variation $\sum_i |h_{i}-h_{i-1}|$; (c) fraction of crossings (sign flips); (d) divergence between early vs.\ late windows, e.g., $\mathrm{KL}(P_{\text{early}}(s) \,\|\, P_{\text{late}}(s))$; (e) ADWIN change-point count/time-to-change.
\paragraph{Visualization.} (i) per-user sparklines with detected change points; (ii) cohort heatmaps by first-review year; (iii) Sankey/alluvial of rating transitions; (iv) wordshift-style plots of terms driving early$\to$late polarity shifts.

\section{Modeling \& Evaluation Rationale (for later milestones)}
\textbf{Why drift methods?} Concept drift surveys motivate adaptive windows and change detection for nonstationary streams. We will compare \emph{static} baselines to \emph{adaptive} detectors (ADWIN/Page--Hinkley). For interpretability we will align change-points with shifts in review lexicon (n-grams) and style. For temporal structure we may explore time-aware sequence models or dynamic topic models to summarize evolving aspects.
\paragraph{Evaluation.} (1) Internal validity: does detected change align with stars trajectory (proxy ground truth)? (2) Robustness: sensitivity to $\alpha$, bin width, smoothing; (3) External validity: cross-domain replication on Yelp. Report user-level AUC for change vs.\ no-change classification under time-based splits, and summary stats over cohorts.

\section{Ethical \& Practical Considerations}
We avoid deanonymization and only report aggregates. Drift signals can be confounded by product mix or platform policy; we will interpret changes cautiously and document class imbalance (positive-skewed ratings).

\section*{Deliverables for Milestone 1}
\begin{itemize}[leftmargin=*, itemsep=2pt]
\item Chosen dataset: Amazon Reviews 2018 (Electronics 5-core). Backup: Yelp Open Dataset.
\item Data schema and preprocessing plan (this document).
\item Starter scripts to ingest, filter, and build per-user trajectories.
\end{itemize}

\section*{Appendix: Repro Steps (Draft)}
\begin{verbatim}
# 1) Download Electronics reviews (5-core or full) from the official page.
# 2) Run prep_amazon_opinion_drift.py to create:
#    - reviews.parquet (row-level)
#    - user_trajectories.parquet (per-user sequences with sentiments)
# 3) Use notebooks to preview drift visualizations.
\end{verbatim}

\begin{thebibliography}{9}
\bibitem{amazon2018}
J.~Ni, J.~Li, J.~McAuley.
\newblock Amazon Review Data (2018), official dataset description and downloads, 2018.

\bibitem{amazon2023}
McAuley Lab.
\newblock Amazon Reviews 2023 (updated collection and schema).

\bibitem{yelp}
Yelp Open Dataset.
\newblock JSON schema for \texttt{review.json} (\texttt{user\_id}, \texttt{date}, \texttt{text}, \texttt{stars}), 2024.

\bibitem{beeradvocate}
J.~McAuley et al.
\newblock BeerAdvocate reviews (1.5M, 10+ years; per-aspect ratings).

\bibitem{gama2014}
J.~Gama, I.~\v{Z}liobaite, A.~Bifet, M.~Pechenizkiy, A.~Bouchachia.
\newblock A Survey on Concept Drift Adaptation.
\newblock \emph{ACM Computing Surveys}, 2014.

\bibitem{adwin2007}
A.~Bifet, R.~Gavalda.
\newblock Learning from Time-Changing Data with Adaptive Windowing (ADWIN).
\newblock \emph{SIAM International Conference on Data Mining}, 2007.

\bibitem{koren2010}
Y.~Koren.
\newblock Collaborative Filtering with Temporal Dynamics.
\newblock \emph{Communications of the ACM}, 2010.

\bibitem{dtm2006}
D.~Blei, J.~Lafferty.
\newblock Dynamic Topic Models.
\newblock \emph{ICML}, 2006.

\bibitem{longitudinal2025}
H.~Liu et al.
\newblock Longitudinal Sentiment Analysis with Textual Data: A Two-Stage Process.
\newblock \emph{Journal of Data Science and Analytics}, 2025.
\end{thebibliography}

\end{document}